{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137dd0e0",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8653c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0509db9",
   "metadata": {},
   "source": [
    "Data loading and preprocessing pipeline for an image classification task using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1832fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      \n",
    "        transforms.RandomHorizontalFlip(),  \n",
    "        transforms.Resize(224),            \n",
    "        transforms.CenterCrop(224),         \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ef8f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names found: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Z']\n",
      "Number of classes found: 23\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "\n",
    "dataset0=datasets.ImageFolder(root=r\"C:\\Users\\tanis\\Downloads\\archive\\ISL_Dataset\" ,transform=None)\n",
    "class_names=dataset0.classes\n",
    "print(f\"Class names found: {class_names}\")\n",
    "print(f\"Number of classes found: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b293e6",
   "metadata": {},
   "source": [
    "High-level interface for PyTorch that helps organize and simplify the process of training deep learning models & applying CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a396b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, transform=transform, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.root_dir = r\"C:\\Users\\tanis\\Downloads\\archive\\ISL_Dataset\"\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n",
    "        n_data = len(dataset)\n",
    "        n_train = int(0.8 * n_data)\n",
    "        n_test = n_data - n_train\n",
    "\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_test])\n",
    "\n",
    "        self.train_dataset = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_dataset = DataLoader(test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_dataset\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7961cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(16 * 54 * 54, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 20)\n",
    "        self.fc4 = nn.Linear(20, len(class_names))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16 * 54 * 54)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        X = self.fc4(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        y_hat = self(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1eb1293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\tanis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | conv1 | Conv2d | 168    | train\n",
      "1 | conv2 | Conv2d | 880    | train\n",
      "2 | fc1   | Linear | 5.6 M  | train\n",
      "3 | fc2   | Linear | 10.2 K | train\n",
      "4 | fc3   | Linear | 1.7 K  | train\n",
      "5 | fc4   | Linear | 483    | train\n",
      "-----------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.449    Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "C:\\Users\\tanis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\tanis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:06<00:00,  2.65it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:07<00:00,  2.52it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:149: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at c:\\Users\\tanis\\AppData\\Local\\Programs\\Microsoft VS Code\\lightning_logs\\version_0\\checkpoints\\epoch=99-step=1800.ckpt\n",
      "Loaded model weights from the checkpoint at c:\\Users\\tanis\\AppData\\Local\\Programs\\Microsoft VS Code\\lightning_logs\\version_0\\checkpoints\\epoch=99-step=1800.ckpt\n",
      "C:\\Users\\tanis\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing DataLoader 0: 100%|██████████| 5/5 [00:00<00:00,  5.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8652482032775879     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0159052610397339     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8652482032775879    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0159052610397339    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    datamodule = DataModule()\n",
    "    datamodule.setup()\n",
    "    model = ConvolutionalNetwork()\n",
    "    trainer = pl.Trainer(max_epochs=100)\n",
    "    trainer.fit(model, datamodule)\n",
    "    datamodule.setup(stage='test')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3674c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A     0.6667    0.8000    0.7273         5\n",
      "           B     0.6250    1.0000    0.7692         5\n",
      "           C     0.8750    1.0000    0.9333         7\n",
      "           D     0.8000    1.0000    0.8889         8\n",
      "           E     1.0000    0.8571    0.9231         7\n",
      "           F     0.8000    1.0000    0.8889         4\n",
      "           G     1.0000    0.7143    0.8333         7\n",
      "           I     0.8333    0.7143    0.7692         7\n",
      "           K     0.8571    0.8571    0.8571         7\n",
      "           L     0.7500    0.6000    0.6667         5\n",
      "           M     1.0000    0.5714    0.7273         7\n",
      "           N     0.6667    0.8000    0.7273         5\n",
      "           O     0.5455    1.0000    0.7059         6\n",
      "           P     1.0000    0.8571    0.9231         7\n",
      "           Q     0.8333    0.5000    0.6250        10\n",
      "           R     0.6667    1.0000    0.8000         6\n",
      "           S     0.8333    0.8333    0.8333         6\n",
      "           T     1.0000    1.0000    1.0000         3\n",
      "           U     1.0000    1.0000    1.0000         5\n",
      "           V     1.0000    0.8333    0.9091         6\n",
      "           W     0.8333    0.8333    0.8333         6\n",
      "           X     1.0000    0.7143    0.8333         7\n",
      "           Z     0.7500    0.6000    0.6667         5\n",
      "\n",
      "    accuracy                         0.8156       141\n",
      "   macro avg     0.8407    0.8298    0.8192       141\n",
      "weighted avg     0.8472    0.8156    0.8141       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")   #\"cuda:0\"\n",
    "\n",
    "model.eval()\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "with torch.no_grad():\n",
    "    for test_data in datamodule.test_dataloader():\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        pred = model(test_images).argmax(dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=class_names,digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
